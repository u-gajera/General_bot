{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install groq\n",
        "!pip install langchain-groq\n",
        "!pip install PyPDF2\n",
        "!pip install langchain_google_genai\n",
        "!pip install langchain\n",
        "!pip install streamlit\n",
        "!pip install langchain_community\n",
        "!pip install python-dotenv\n",
        "!pip install pypdf\n",
        "!pip install google-cloud-aiplatform>=1.38\n",
        "!pip install fpdf\n",
        "!pip install google-auth"
      ],
      "metadata": {
        "id": "TlewNocaxOl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqYdk-4krffA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from google.colab import files\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from fpdf import FPDF\n",
        "import re\n",
        "import time\n",
        "\n",
        "# Step 1: Initialize API keys\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    #groq_api_key = getpass(\"Enter your GROQ API Key: \")\n",
        "    os.environ[\"GROQ_API_KEY\"] = \"gsk_AlLaoagluFZqjG8LmGEKWGdyb3FYEX49qIfOkYNwiJXq1nMIbHK\"\n",
        "else:\n",
        "    groq_api_key = os.environ[\"GROQ_API_KEY\"]\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    #google_api_key = getpass(\"Enter your Google API Key: \")\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDaWZ8eYeDJWjzeNMR43nfJNTikX3weQM\"\n",
        "else:\n",
        "    google_api_key = os.environ[\"GOOGLE_API_KEY\"]\n",
        "\n",
        "# Step 2: Upload files\n",
        "print(\"Please upload your PDF files.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 3: Save uploaded files locally\n",
        "pdf_files = list(uploaded.keys())\n",
        "print(f\"Uploaded files: {pdf_files}\")\n",
        "\n",
        "for file_name in pdf_files:\n",
        "    with open(file_name, \"wb\") as f:\n",
        "        f.write(uploaded[file_name])\n",
        "\n",
        "# Step 4: Helper Functions\n",
        "def extract_urls(text):\n",
        "    \"\"\"Extract URLs from the given text.\"\"\"\n",
        "    url_pattern = r'(https?://[^\\s]+)'\n",
        "    return re.findall(url_pattern, text)\n",
        "\n",
        "def create_pdf(text, filename=\"response.pdf\"):\n",
        "    \"\"\"Save the given text as a PDF.\"\"\"\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()he YouTube links will display correctly once the frontend is fully developed and integrated. Let me know if you have any further questio\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.multi_cell(0, 10, text.encode('latin-1', 'replace').decode('latin-1'))\n",
        "    pdf.output(filename, dest='F')\n",
        "\n",
        "# Step 5: Process Files\n",
        "def process_uploaded_pdfs(pdf_paths):\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "    all_documents = []\n",
        "    extracted_urls = {}\n",
        "\n",
        "    for pdf_path in pdf_paths:\n",
        "        loader = PyPDFLoader(pdf_path)\n",
        "        documents = loader.load()\n",
        "        all_documents.extend(documents)\n",
        "\n",
        "        # Extract URLs from each document\n",
        "        urls = []\n",
        "        for doc in documents:\n",
        "            urls.extend(extract_urls(doc.page_content))\n",
        "        extracted_urls[pdf_path] = urls\n",
        "\n",
        "    # Split documents and create vector embeddings\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
        "    final_documents = text_splitter.split_documents(all_documents)\n",
        "    vectors = FAISS.from_documents(final_documents, embeddings)\n",
        "\n",
        "    return vectors, extracted_urls\n",
        "\n",
        "# Step 6: Load PDFs and Create Vector Embeddings\n",
        "vectors, extracted_urls = process_uploaded_pdfs(pdf_files)\n",
        "print(f\"Processed {len(pdf_files)} PDF(s). Vector embeddings are ready.\")\n",
        "\n",
        "for pdf, urls in extracted_urls.items():\n",
        "    print(f\"Extracted URLs from {pdf}: {', '.join(urls)}\")\n",
        "\n",
        "# Step 7: Initialize Language Model and Prompt\n",
        "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"mixtral-8x7b-32768\")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Answer the following questions based on the provided context ONLY.\n",
        "Please provide detailed, accurate, and professional responses.\n",
        "Where possible, include references to URLs or source documents.\n",
        "<context>\n",
        "{context}\n",
        "<context>\n",
        "Question: {input}\n",
        "\"\"\")\n",
        "\n",
        "# Main Loop\n",
        "while True:\n",
        "    user_question = input(\"Enter your question about the uploaded documents (or type 'exit' to quit): \")\n",
        "\n",
        "    if user_question.lower() == \"exit\":\n",
        "        print(\"Exiting the program. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    if user_question.strip():\n",
        "        # Step 9: Generate Response\n",
        "        document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "        retriever = vectors.as_retriever()\n",
        "        retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
        "\n",
        "        # Measure response time\n",
        "        start = time.process_time()\n",
        "        response_with_docs = retrieval_chain.invoke({'input': user_question})\n",
        "        elapsed_time = time.process_time() - start\n",
        "\n",
        "        # Extract relevant documents and URLs\n",
        "        retrieved_docs = response_with_docs.get('source_documents', [])\n",
        "        relevant_urls = []\n",
        "        for doc in retrieved_docs:\n",
        "            doc_urls = extract_urls(doc.page_content)\n",
        "            relevant_urls.extend(doc_urls)\n",
        "\n",
        "        # Remove duplicates\n",
        "        relevant_urls = list(set(relevant_urls))\n",
        "\n",
        "        # Prepare response text\n",
        "        response_text = response_with_docs['answer']\n",
        "        if relevant_urls:\n",
        "            response_text += \"\\n\\nRelevant References:\\n\" + \"\\n\".join(relevant_urls)\n",
        "\n",
        "        # Display response and save to PDF\n",
        "        print(f\"Response time: {elapsed_time:.2f} seconds\")\n",
        "        print(response_text)\n",
        "        create_pdf(response_text)\n",
        "        print('The response has been saved to a PDF file as \"response.pdf\". Download it from the Colab file manager.')\n",
        "    else:\n",
        "        print(\"Please provide a valid question!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vGYp0rL7rsRP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
